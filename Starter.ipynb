{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport random\nfrom operator import add\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\nfrom __future__ import unicode_literals\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Define gridworld class\nclass Gridworld:\n    def __init__(self, gridworld_length=2, gridworld_width=10, num_obstacles=10,\n                 collisionReward= -1, destinationReward= 10, defaultReward= 0, failChance= 0.1, gamma= 0.9):\n        self.gridworld_length = gridworld_length\n        self.gridworld_width = gridworld_width\n        self.grid = np.zeros((gridworld_length,gridworld_width))\n        self.ds_actions = {\"u\": [0,-1], \"d\": [0,1], \"l\": [-1,0], \"r\": [1,0]}\n        self.actions= list(self.ds_actions.keys()),\n        self.num_obstacles = num_obstacles\n        self.source, self.destination, self.obstacle_positions = self.initiate_gridworld()\n        self.agent = self.source\n        self.collisionReward = collisionReward\n        self.destinationReward = destinationReward\n        self.defaultReward = defaultReward\n        self.failChance = failChance\n        self.gamma = gamma\n\n    def random_coord(self):\n        return [random.randint(0, self.gridworld_length-1), random.randint(0, self.gridworld_width-1)]\n\n    def initiate_gridworld(self):\n        # add a random source and destination to the gridworld\n        source = self.random_coord()\n        destination = self.random_coord()\n        while destination == source:\n            destination = self.random_coord()\n\n        # add some random obstacles to the gridworld, making sure that the source and destination are not obstacles\n        obstacle_positions = []\n        print(self.num_obstacles)\n        \n        while len(obstacle_positions) < self.num_obstacles:\n            position = self.random_coord()\n            if position != source or position != destination:\n                obstacle_positions.append(position)\n        print(source, destination, obstacle_positions)\n        return source, destination, obstacle_positions\n\n    def takeAction(self, a):\n        # take action with probability 0.1, stay in same state with probability 0.9\n        if random.random() < 1 - self.failChance:\n            print(self.agent, self.ds_actions[a])\n            new_agent = list(map(add, self.agent, self.ds_actions[a]))\n            print(new_agent)\n            # if collision\n            if new_agent[0] < 0 or new_agent[0] >= self.gridworld_length or \\\n                new_agent[1] < 0 or new_agent[1] >= self.gridworld_width or \\\n                new_agent in self.obstacle_positions:\n                return self.collisionReward\n            self.agent = new_agent\n            if new_agent == self.destination:\n                return self.destinationReward\n        return self.defaultReward\n\n    def print_gridworld(self):\n        for row in range(self.gridworld_length):\n            for col in range(self.gridworld_width):\n                if [row,col] in self.obstacle_positions:\n                    print('O', end=' ')\n                elif [row,col] == self.destination:\n                    print('D', end=' ')\n                elif [row, col] == self.agent:\n                    print('A', end=' ')\n                else:\n                    print('-', end=' ')\n            print()\n    \n    def gridworld_to_arr(self):\n        char_grid = np.zeros([self.gridworld_length, self.gridworld_width]).astype('<U1')\n        for row in range(self.gridworld_length):\n            for col in range(self.gridworld_width):\n                if [row,col] in self.obstacle_positions:\n                    char_grid[row, col] = 'O'\n                elif [row,col] == self.destination:\n                    char_grid[row, col] = 'D'\n                elif [row, col] == self.agent:\n                    char_grid[row, col] = 'A'\n                else:\n                    char_grid[row, col] = '-'\n        return char_grid\n    \n    ",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Visualization helper functions\ndef chars_to_num(char_grid):\n    \"\"\"\n    Creates a copy of a 2D character gridworld converted into a 2D array of integers\n    for easy visualization in matplotlib. The mapping is as follows:\n    '-' --> 0\n    'A' --> 1 \n    'O' --> 2\n    'D' --> 3\n    \"\"\"\n    num_grid = char_grid.copy()\n    num_grid[num_grid == '-'] = 0\n    num_grid[num_grid == 'A'] = 1\n    num_grid[num_grid == 'O'] = 2\n    num_grid[num_grid == 'D'] = 3\n    num_grid = num_grid.astype('int64')\n    return num_grid\n\ndef chars_to_icons(char_grid):\n    \"\"\"\n    Creates a copy of a 2D character gridworld converted into a 2D array of integers\n    for easy visualization in matplotlib. The mapping is as follows:\n    '-' --> 'üçÇ'\n    'A' --> 'ü§ñ' \n    'O' --> 'üå≤'\n    'D' --> 'üßóüèΩ'\n    \"\"\"\n    icon_grid = char_grid.copy()\n    icon_grid[icon_grid == '-'] = 'üçÇ'\n    icon_grid[icon_grid == 'A'] = 'ü§ñ'\n    icon_grid[icon_grid == 'O'] = 'üå≤'\n    icon_grid[icon_grid == 'D'] = 'üßó'\n    return icon_grid\n\ndef visualize_grid(char_grid):\n    \"\"\"\n    Visualize a 2D grid of characters in matplotlib with emojis\n    \"\"\"\n    colors = ['saddlebrown', 'red', 'green', 'yellow']\n    cmap = ListedColormap(colors)\n    fig, ax = plt.subplots()\n    num_grid = chars_to_num(char_grid)\n    icon_grid = chars_to_icons(char_grid)\n\n    for y in range(char_grid.shape[0]):\n       for x in range(char_grid.shape[1]):\n          plt.text(x , y, icon_grid[y, x],\n             horizontalalignment='center',\n             verticalalignment='center',\n             fontname='Segoe UI Emoji'\n          )\n    ax.matshow(num_grid, cmap=cmap, vmin=0, vmax=len(colors))\n    \n    ",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#policy score calculator\ndef policy_score(rewards, discount_factor):\n    \"\"\"\n    Calculates the score of a policy using a list of rewards and a discount factor\n    \"\"\"\n    score = 0\n    for i in range(len(rewards)):\n        score += (discount_factor**i)*rewards[i]\n    return score\n    ",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# simulate random policy\nrewards=[]\ng = Gridworld(gridworld_length=10)\n# simulate the agent's actions\nfor _ in range(20):\n    g.print_gridworld()\n    visualize_grid(g.gridworld_to_arr())\n    # choose a random action\n    action = random.choice(g.actions[0])\n    print(f'Taking action: {action}')\n    # take the action and update the agent's position\n    reward = g.takeAction(action)\n    print(\"Action: \", action, \"Reward: \", reward)\n    rewards.append(reward)    \n    \ngamma = 1\nprint(rewards)\nprint(policy_score(rewards, gamma))",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}